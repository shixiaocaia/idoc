问题收集
===

> 参考链接
>
> - [Tinywebserver](https://zhuanlan.zhihu.com/p/368154495)
> - [(203条消息) 【面试专栏】自己整理的WebServer项目问题_温酒煮青梅的博客-CSDN博客](https://blog.csdn.net/weixin_44484715/article/details/120825122?ops_request_misc={"request_id"%3A"164801822216780366515645"%2C"scm"%3A"20140713.130102334.pc_all."}&request_id=164801822216780366515645&biz_id=0&spm=1018.2226.3001.4187)
> - [(203条消息) 近四十场面试汇聚成的超全Web服务器面经总结_Netfishless的博客-CSDN博客_web服务器项目面试](https://blog.csdn.net/ClaireSy/article/details/122436929?ops_request_misc={"request_id"%3A"164801870116782089383195"%2C"scm"%3A"20140713.130102334.."}&request_id=164801870116782089383195&biz_id=0&spm=1018.2226.3001.4187)
> - [web服务器项目部分问题汇总 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/269247362)
> - [(90 封私信 / 83 条消息) 半同步半反应堆 - 搜索结果 - 知乎 (zhihu.com)](https://www.zhihu.com/search?type=content&q=半同步半反应堆)

## 自己问题



## 为什么要做这样一个项目



## 介绍下这个项目

- 使用线程池 + 非阻塞socket + epoll(ET和LT均实现) + 事件处理(Reactor和模拟Proactor均实现) 的并发模型；
- 使用状态机解析HTTP请求报文，支持解析GET和POST请求
- 访问服务器数据库实现web端用户注册、登录功能，可以请求服务器图片和视频文件；
- 实现同步/异步日志系统，记录服务器运行状态；
- 经Webbench压力测试可以实现上万的并发连接数据交换；

## 线程池

- 线程池与多线程的设计思路
  - 设计一个任务队列，作为临界资源
  - 初始化n个线程，开始运行，对任务队列加锁取拿取任务执行
  - 当任务队列为空时，所有子线程（工作线程）阻塞（pthread_cond_wait）
  - 主线程感知到内核事件表上有事件发生时，将任务添加到任务队列中，唤醒睡眠的工作线程（pthread_cond_signal pthread_cond_broadcast）

- 线程的同步机制有哪些？
  - 信号量、条件变量、互斥量等；
- 线程池中的工作线程是一直等待吗？
  - 是的，等待新任务的唤醒；
- 你的线程池工作线程处理完一个任务后的状态是什么？
  - 如果请求队列为空，则该线程进入线程池中等待；
  - 若不为空，则该线程跟其他线程一起进行任务的竞争；
- 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？
  - 该项目是基于IO复用的并发模式。
  - 如果速度还是慢，那就只能够增大线程池容量，或者考虑集群分布式的做法。
  - 需要注意的是，不是一个客户连接就对应一个线程！如果真是如此，淘宝双12服务器早就崩了！当客户连接有事件需要处理的时，epoll会进行事件提醒，而后讲对应的任务加入请求队列，等待工作线程竞争执行。
- 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?
  - 会，因为线程的数量是固定的，如果一个客户请求长时间占用着线程资源，势必会影响到服务器对外的整体响应速度。
  - 解决的策略可以是给每一个线程处理任务设定一个时间阈值，当某一个客户请求时间过长，则将其置于任务请求最后，或断开连接。

## 并发模型

- 简单说一下服务器使用的并发模型？
  - 该项目选用的半同步半反应堆的并发模型。
  - 以Proactor模式为例的工作流程即是：
    - 主线程充当**异步线程**，负责监听所有socket上的事件
    - 若有新请求到来，主线程接收之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件
    - 如果连接socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成请求对象插入到请求队列中
    - 所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权

- reactor、proactor、主从reactor模型的区别？

  - **Reactor模式**：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程，将socket可读可写事件放入请求队列，读写数据、接受新连接及处理客户请求均在工作线程中完成。(需要区别读和写事件)

  - Proactor模式：主线程和内核负责处理读写数据、接受新连接等I/O操作，工作线程仅负责业务逻辑（给予相应的返回url），如处理客户请求。

  - 主从Reactor模式：核心思想是，主反应堆线程只负责分发Acceptor连接建立，已连接套接字上的I/O事件交给sub-reactor负责分发。其中 sub-reactor的数量，可以根据CPU的核数来灵活设置。[下图](https://link.zhihu.com/?target=https%3A//www.cnblogs.com/-wenli/p/13343397.html)即是其工作流程：

- 你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？
  - 先说说其他的复用方式吧，比较常用的有三种：select/poll/epoll。本项目之所以采用epoll，参考问题（[Why is epoll faster than select?](https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/17355593/why-is-epoll-faster-than-select)）
  - 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，**每次调用都需要将整个集合拷贝到内核态**；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要**执行一个系统调用**。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。
  - select使用线性表描述文件描述符集合，**文件描述符有上限**；poll使用**链表来描述**；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
  - select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，**它们会采用遍历的方式**，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，**会自动触发epoll回调函数通知epoll文件描述符**，然后内核将这些就绪的文件描述符放到之前提到的**ready list中等待epoll_wait调用后被处理**。
  - select和poll都只能工作在**相对低效的LT模式下**，而epoll同时支持LT和ET模式。
  - 综上，**当监测的fd数量较小**，且各个fd都很活跃的情况下，建议使用select和poll；**当监听的fd数量较多**，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

- 客户端断开连接，服务端epoll监听到的事件是什么

  - 在使用 epoll 时，客户端正常断开连接（调用 close()），在服务器端会触发一个 epoll 事件。在早期的内核中，这个 epoll 事件一般是 EPOLLIN，即 0x1，代表连接可读。
  - 连接池检测到某个连接发生 EPOLLIN 事件且没有错误后，会认为有请求到来，将连接交给上层进行处理。这样一来，上层尝试在对端已经 close() 的连接上读取请求，只能读到 EOF（文件末尾），会认为发生异常，报告一个错误。
  - 后期的内核中增加了 EPOLLRDHUP 事件，代表对端断开连接。对端连接断开触发的 epoll 事件会包含 EPOLLIN | EPOLLRDHUP，即 0x2001。有了这个事件，对端断开连接的异常就可以在底层进行处理了，不用再移交到上层

- EPOLL的线程安全

  - 简要结论就是epoll是通过锁来保证线程安全的, epoll中粒度最小的自旋锁ep->lock(spinlock)用来保护就绪的队列, 互斥锁ep->mtx用来保护epoll的重要数据结构红黑树

    主要的两个函数：

    - epoll_ctl()：当需要根据不同的operation通过ep_insert() 或者ep_remove()等接口对epoll自身的数据结构进行操作时都提前获得了ep->mtx锁
    - epll_wait()：获得自旋锁 ep->lock来保护就绪队列

- 非阻塞IO和阻塞IO区别

## HTTP报文解析

- 用了状态机啊，为什么要用状态机？

——有限状态机，是一种抽象的理论模型，它能够把有限个变量描述的状态变化过程，以可构造可验证的方式呈现出来。比如，封闭的有向图。有限状态机可以通过if-else,switch-case和函数指针来实现，从软件工程的角度看，主要是为了封装逻辑。有限状态机一种逻辑单元内部的一种高效编程方法，在服务器编程中，服务器可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂。

- 状态机的转移图画一下？

- https协议为什么安全？

  - 连接建立阶段基于ssl安全验证；
  - 数据传输阶段加密
  - 进一步了解可以百度

- HTTPS的SSL连接过程

  ![img](https://pic2.zhimg.com/v2-e03691ec1b4cec38f18360dcc4b2e7ad_b.jpg)

- GET和POST的区别？

  - GET在浏览器回退时是无害的，而POST会再次提交请求。
  - GET产生的URL地址可以被Bookmark，而POST不可以。
  - GET请求会被浏览器主动cache，而POST不会，除非手动设置。
  - GET请求只能进行url编码，而POST支持多种编码方式。
  - GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
  - GET请求在URL中传送的参数是有长度限制的，而POST么有。
  - 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
  - GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
  - GET参数通过URL传递，POST放在Request body中。

  ---

  - 本质上都是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 
  - GET产生一个TCP数据包；POST产生两个TCP数据包。
    - 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；
    - 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。
  - 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
  - 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

## 定时器

- 为什么要用定时器
  - 处理定时任务，或者非活跃连接，节省系统资源；
- 说一下定时器的工作原理？
  - 服务器就为各事件分配一个定时器。该项目使用SIGALRM信号来实现定时器，首先每一个定时事件都处于一个升序链表上，**通过alarm()函数周期性触发SIGALRM信号**，而后信号回调函数利用管道通知主循环，主循环接收到信号之后对升序链表上的定时器进行处理：若一定时间内无数据交换则关闭连接。
- 双向链表啊，删除和添加的时间复杂度说一下？还可以优化吗？
  - 添加一般情况下都是O(N)，删除只需要O(1)。从双向链表的方式优化不太现实，可以考虑使用最小堆、或者跳表的数据结构，跳表详见。‘
- 最小堆优化？说一下时间复杂度和工作原理
  - 最小堆以每个定时器的过期时间进行排序，最小的定时器位于堆顶，当SIGALRM信号触发tick（）函数时执行过期定时器清除，如果堆顶的定时器时间过期，则删除，并重新建堆，再判定是否过期，如此循环直到未过期为止。
  - 插入，O(logn)；
  - 删除，O(logN)；
- 为什么管道写端为非阻塞
  - send是将信息发送给套接字缓冲区，如果缓冲区满了，则会阻塞，这时候会进一步增加信号处理函数的执行时间，为此，将其修改为非阻塞。

- 除了管道还有什么信息交换方式

- 中断系统调用
  - 如果程序在执行处于阻塞状态的系统调用时接收到信号，并且我们为该信号设置了信
    号处理函数，则默认情况下系统调用将被中断，并且errno被设置为ENTR。我们可以使
    用sigaction函数（见后文）为信号设置SA_RESTART标志以自动重启被该信号中断的系
    统调用。

## 日志

- 初始化服务器时，利用单例模式初始化日志系统，根据配置文件确认是同步还是异步写入的方式。
- 为什么要异步？和同步的区别是什么？
  - 同步方式写入日志时会产生比较多的系统调用，若是某条日志信息过大，会阻塞日志系统，造成系统瓶颈。
  - 异步方式采用生产者-消费者模型，具有较高的并发能力。
- 现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？
  - 为了便于故障排查，或服务器状态分析，看是否需要维护；
  - 可以使用消息队列进行消息的分发，例如mqtt、rabitmq等等；

## 数据库

- 登录设计的流程是什么
  - 具体的涉及到**载入数据库表，提取用户名和密码，注册登录流程与页面跳转**。
  - 载入数据库表，结合代码将数据库中的数据载入到服务器中；
  - 提取用户名和密码，结合代码对报文进行解析，提取用户名和密码；
  - 注册登录流程，结合代码对描述服务器进行注册和登录校验的流程；
  - 页面跳转，结合代码对页面跳转机制进行详解
- 你这个保存状态了吗？如果要保存，你会怎么做？
  - 可以利用session或者cookie的方式进行状态的保存。
  - cookie其实就是服务器给客户分配了一串“身份标识”，比如“123456789happy”这么一串字符串。每次客户发送数据时，都在HTTP报文附带上这个字符串，服务器就知道你是谁了；
  - session是保存在服务器端的状态，每当一个客户发送HTTP报文过来的时候，服务器会在自己记录的用户数据中去找，类似于核对名单；
- 登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使load到本地后hash，也是很耗时的，你要怎么优化？
  - 这个问题的关键在于大数据量情况下的用户登录验证怎么进行？将所有的用户信息加载到内存中耗时耗利，对于大数据最遍历的方法就是进行hash，利用hash建立多级索引的方式来加快用户验证。具体操作如下：
  - 首先，将10亿的用户信息，利用大致缩小1000倍的hash算法进行hash，这时就获得了100万的hash数据，每一个hash数据代表着一个用户信息块（一级）；
  - 而后，再分别对这100万的hash数据再进行hash，例如最终剩下1000个hash数据（二级）。
  - 在这种方式下，服务器只需要保存1000个二级hash数据，当用户请求登录的时候，先对用户信息进行一次hash，找到对应信息块（二级），在读取其对应的一级信息块，最终找到对应的用户数据。
- 用过mysql，redis了解吗

## 压测

**服务器并发量测试过吗？怎么测试的**？

- 测试过，利用webbench，至少满足万余的并发量。

**webbench是什么？介绍一下原理**

- 是一款轻量级的网址压力测试工具，可以实现高达3万的并发测试。
- 其原理：Webbench实现的核心原理是：父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。

**测试的时候有没有遇到问题**？



## 综合问题

- 说一下前端发送请求后，服务器处理的过程，中间涉及哪些协议？
  - HTTP协议、TCP、IP协议等，计算机网络的知识。
- 性能缺陷
  - 现在的架构没有缓存，每一次数据请求都是对数据库的访问，当用户量大的时候会造成整体性能下降；
- 怎样应对服务器的大流量、高并发
  - 客户端：
    - 尽量减少请求数量：依靠客户端自身的缓存或处理能力
    - 尽量减少对服务端资源的不必要耗费：重复使用某些资源，如连接池
  - 服务端：
    - 增加资源供给：更大的网络带宽，使用更高配置的服务器
    - 请求分流：使用集群,分布式的系统架构
    - 应用优化：使用更高效的编程语言,优化处理业务逻辑的算法
- VSCODE调试多线程
- 手撕一个最简单的server端服务器

## 感受

- 不是的，主要是分析它的架构，和一些代码写法，并加上备注。
  重敲一遍性价比很低，建议考虑重构，比如使用golong或者java重新写一遍。
